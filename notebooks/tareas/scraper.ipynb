{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scraping de Noticias y Serialización en JSONL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "- URL: https://www.reuters.com/world/\n",
        "\n",
        "   - Extraer al menos 20 noticias recientes con los siguientes campos:\n",
        "     - id (un identificador único, puedes generar un hash o número incremental)\n",
        "     - titulo\n",
        "     - fecha (en formato ISO si está disponible)\n",
        "     - url\n",
        "     - fuente (nombre del sitio)\n",
        "     - autor\n",
        "     - capturado_ts (timestamp de la captura en UTC)\n",
        "     - resumen (campo adicional de interés)\n",
        "\n",
        "3. **Serialización en JSONL:**\n",
        "   - Guardar cada noticia como un objeto JSON en una línea dentro del archivo `data/raw/noticias.jsonl`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import os\n",
        "import hashlib\n",
        "from datetime import datetime, timezone\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encontrados 24 posibles elementos de noticias\n",
            "Guardado 20 noticias en ../../data/raw/noticias.jsonl\n"
          ]
        }
      ],
      "source": [
        "def scrape_bbc_mundo_tecnologia(url=\"https://www.bbc.com/mundo/topics/cyx5krnw38vt\", num_news=20):\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "    except Exception as e:\n",
        "        print(f\"Error en la petición HTTP: {e}\")\n",
        "        return []\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    noticias = []\n",
        "    news_items = soup.find_all('li', class_='bbc-t44f9r')\n",
        "    print(f\"Encontrados {len(news_items)} posibles elementos de noticias\")\n",
        "    for i, item in enumerate(news_items):\n",
        "        if len(noticias) >= num_news:\n",
        "            break\n",
        "        try:\n",
        "            # Título y URL\n",
        "            h2 = item.find('h2')\n",
        "            a = h2.find('a') if h2 else None\n",
        "            if not a:\n",
        "                continue\n",
        "            titulo = a.get_text().strip()\n",
        "            noticia_url = a['href']\n",
        "            if not noticia_url.startswith('http'):\n",
        "                noticia_url = f\"https://www.bbc.com{noticia_url}\"\n",
        "            # Fecha\n",
        "            fecha_elem = item.find('time')\n",
        "            fecha = fecha_elem.get('datetime') if fecha_elem and fecha_elem.has_attr('datetime') else (fecha_elem.get_text().strip() if fecha_elem else \"Fecha no disponible\")\n",
        "            # Resumen (opcional, puede ser el alt de la imagen o el texto del h2)\n",
        "            img = item.find('img')\n",
        "            resumen = img['alt'].strip() if img and img.has_attr('alt') else titulo\n",
        "            # Autor: requiere entrar a la noticia\n",
        "            autor = \"Autor no disponible\"\n",
        "            try:\n",
        "                art_resp = requests.get(noticia_url, headers=headers, timeout=10)\n",
        "                art_resp.raise_for_status()\n",
        "                art_soup = BeautifulSoup(art_resp.content, 'html.parser')\n",
        "                byline_section = art_soup.find('section', {'role': 'region', 'aria-labelledby': 'article-byline'})\n",
        "                if byline_section:\n",
        "                    autor_span = byline_section.find('span', class_='bbc-of1z6f')\n",
        "                    if autor_span:\n",
        "                        autor = autor_span.get_text().strip()\n",
        "            except Exception as e:\n",
        "                pass\n",
        "            # ID único\n",
        "            # Extraer el id de la noticia desde el URL (lo que sigue a 'articles/')\n",
        "            noticia_id = \"id_no_encontrado\"\n",
        "            match = re.search(r'/articles/([^/?#]+)', noticia_url)\n",
        "            if match:\n",
        "                noticia_id = match.group(1)\n",
        "            # Timestamp de captura\n",
        "            capturado_ts = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
        "            noticia = {\n",
        "                \"id\": noticia_id,\n",
        "                \"titulo\": titulo,\n",
        "                \"fecha\": fecha,\n",
        "                \"url\": noticia_url,\n",
        "                \"fuente\": \"BBC Mundo Tecnología\",\n",
        "                \"autor\": autor,\n",
        "                \"capturado_ts\": capturado_ts,\n",
        "                \"resumen\": resumen[:200] + \"...\" if len(resumen) > 200 else resumen\n",
        "            }\n",
        "            noticias.append(noticia)\n",
        "        except Exception as e:\n",
        "            print(f\"Error procesando noticia {i}: {e}\")\n",
        "            continue\n",
        "    return noticias\n",
        "\n",
        "output_path = \"../../data/raw/noticias.jsonl\"\n",
        "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "\n",
        "noticias = scrape_bbc_mundo_tecnologia(num_news=20)\n",
        "\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for noticia in noticias:\n",
        "        f.write(json.dumps(noticia, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(f\"Guardado {len(noticias)} noticias en {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"id\": \"c4gv9r1120mo\", \"titulo\": \"Los cerdos y los insectos que están ayudando a encontrar a los desaparecidos en México\", \"fecha\": \"2025-10-01\", \"url\": \"https://www.bbc.com/mundo/articles/c4gv9r1120mo\", \"fuente\": \"BBC Mundo Tecnología\", \"autor\": \"Alejandro Millán Valencia\", \"capturado_ts\": \"2025-10-03T04:51:32Z\", \"resumen\": \"Científicos preparan una fosa para poner el cuerpo de un animal para ser analizados en su proceso de descomposición.\"}\n",
            "{\"id\": \"cz0827j1nvdo\", \"titulo\": \"Las mujeres de Afganistán pierden su \\\"última esperanza\\\" tras el bloqueo de internet por parte del Talibán\", \"fecha\": \"2025-10-01\", \"url\": \"https://www.bbc.com/mundo/articles/cz0827j1nvdo\", \"fuente\": \"BBC Mundo Tecnología\", \"autor\": \"Mahfouz Zubaide\", \"capturado_ts\": \"2025-10-03T04:51:32Z\", \"resumen\": \"Mujer afgana\"}\n",
            "{\"id\": \"ckgqry9x72ko\", \"titulo\": \"\\\"Nunca más tendrás que volver a trabajar\\\": cómo un grupo de delincuentes intentó sobornarme para hackear la BBC\", \"fecha\": \"2025-09-30\", \"url\": \"https://www.bbc.com/mundo/articles/ckgqry9x72ko\", \"fuente\": \"BBC Mundo Tecnología\", \"autor\": \"Joe Tidy\", \"capturado_ts\": \"2025-10-03T04:51:33Z\", \"resumen\": \"Joe Tidy looking down at a phone. He has short brown hair and is wearing a light blue shirt.\"}\n"
          ]
        }
      ],
      "source": [
        "# Mostrar las primeras 3 líneas del archivo JSONL generado\n",
        "with open(output_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "        print(line.strip())\n",
        "        if i >= 2:\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número total de registros: 20\n",
            "\n",
            "Porcentaje de valores nulos por campo:\n",
            "id              0.0\n",
            "titulo          0.0\n",
            "fecha           0.0\n",
            "url             0.0\n",
            "fuente          0.0\n",
            "autor           0.0\n",
            "capturado_ts    0.0\n",
            "resumen         0.0\n",
            "dtype: float64\n",
            "\n",
            "Duplicados por id: 0\n",
            "Duplicados por url: 0\n",
            "\n",
            "Fechas con formato válido (YYYY-MM-DD): 20 / 20\n",
            "URLs con formato válido: 20 / 20\n",
            "\n",
            "Resumen de calidad de datos:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>titulo</th>\n",
              "      <th>fecha</th>\n",
              "      <th>url</th>\n",
              "      <th>fuente</th>\n",
              "      <th>autor</th>\n",
              "      <th>capturado_ts</th>\n",
              "      <th>resumen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c4gv9r1120mo</td>\n",
              "      <td>Los cerdos y los insectos que están ayudando a...</td>\n",
              "      <td>2025-10-01</td>\n",
              "      <td>https://www.bbc.com/mundo/articles/c4gv9r1120mo</td>\n",
              "      <td>BBC Mundo Tecnología</td>\n",
              "      <td>Alejandro Millán Valencia</td>\n",
              "      <td>2025-10-03T04:51:32Z</td>\n",
              "      <td>Científicos preparan una fosa para poner el cu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cz0827j1nvdo</td>\n",
              "      <td>Las mujeres de Afganistán pierden su \"última e...</td>\n",
              "      <td>2025-10-01</td>\n",
              "      <td>https://www.bbc.com/mundo/articles/cz0827j1nvdo</td>\n",
              "      <td>BBC Mundo Tecnología</td>\n",
              "      <td>Mahfouz Zubaide</td>\n",
              "      <td>2025-10-03T04:51:32Z</td>\n",
              "      <td>Mujer afgana</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ckgqry9x72ko</td>\n",
              "      <td>\"Nunca más tendrás que volver a trabajar\": cóm...</td>\n",
              "      <td>2025-09-30</td>\n",
              "      <td>https://www.bbc.com/mundo/articles/ckgqry9x72ko</td>\n",
              "      <td>BBC Mundo Tecnología</td>\n",
              "      <td>Joe Tidy</td>\n",
              "      <td>2025-10-03T04:51:33Z</td>\n",
              "      <td>Joe Tidy looking down at a phone. He has short...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c20z3gnd9l0o</td>\n",
              "      <td>El Talibán corta internet y causa un apagón de...</td>\n",
              "      <td>2025-09-30</td>\n",
              "      <td>https://www.bbc.com/mundo/articles/c20z3gnd9l0o</td>\n",
              "      <td>BBC Mundo Tecnología</td>\n",
              "      <td>Anbarasan Ethirajan</td>\n",
              "      <td>2025-10-03T04:51:33Z</td>\n",
              "      <td>Hombre en Afganistán revisa su teléfono.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c4gk21318dxo</td>\n",
              "      <td>La familia Ellison, la nueva dinastía de los m...</td>\n",
              "      <td>2025-09-29</td>\n",
              "      <td>https://www.bbc.com/mundo/articles/c4gk21318dxo</td>\n",
              "      <td>BBC Mundo Tecnología</td>\n",
              "      <td>Natalie Sherman</td>\n",
              "      <td>2025-10-03T04:51:34Z</td>\n",
              "      <td>Larry Ellison (izq.) junto a su hija Megan y s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id                                             titulo  \\\n",
              "0  c4gv9r1120mo  Los cerdos y los insectos que están ayudando a...   \n",
              "1  cz0827j1nvdo  Las mujeres de Afganistán pierden su \"última e...   \n",
              "2  ckgqry9x72ko  \"Nunca más tendrás que volver a trabajar\": cóm...   \n",
              "3  c20z3gnd9l0o  El Talibán corta internet y causa un apagón de...   \n",
              "4  c4gk21318dxo  La familia Ellison, la nueva dinastía de los m...   \n",
              "\n",
              "        fecha                                              url  \\\n",
              "0  2025-10-01  https://www.bbc.com/mundo/articles/c4gv9r1120mo   \n",
              "1  2025-10-01  https://www.bbc.com/mundo/articles/cz0827j1nvdo   \n",
              "2  2025-09-30  https://www.bbc.com/mundo/articles/ckgqry9x72ko   \n",
              "3  2025-09-30  https://www.bbc.com/mundo/articles/c20z3gnd9l0o   \n",
              "4  2025-09-29  https://www.bbc.com/mundo/articles/c4gk21318dxo   \n",
              "\n",
              "                 fuente                      autor          capturado_ts  \\\n",
              "0  BBC Mundo Tecnología  Alejandro Millán Valencia  2025-10-03T04:51:32Z   \n",
              "1  BBC Mundo Tecnología            Mahfouz Zubaide  2025-10-03T04:51:32Z   \n",
              "2  BBC Mundo Tecnología                   Joe Tidy  2025-10-03T04:51:33Z   \n",
              "3  BBC Mundo Tecnología        Anbarasan Ethirajan  2025-10-03T04:51:33Z   \n",
              "4  BBC Mundo Tecnología            Natalie Sherman  2025-10-03T04:51:34Z   \n",
              "\n",
              "                                             resumen  \n",
              "0  Científicos preparan una fosa para poner el cu...  \n",
              "1                                       Mujer afgana  \n",
              "2  Joe Tidy looking down at a phone. He has short...  \n",
              "3           Hombre en Afganistán revisa su teléfono.  \n",
              "4  Larry Ellison (izq.) junto a su hija Megan y s...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "with open('../../data/raw/noticias.jsonl', 'r', encoding='utf-8') as f:\n",
        "    records = [json.loads(line) for line in f if line.strip()]\n",
        "\n",
        "df = pd.DataFrame(records)\n",
        "\n",
        "# 1. Número total de registros\n",
        "num_registros = len(df)\n",
        "print(f\"Número total de registros: {num_registros}\")\n",
        "\n",
        "# 2. Porcentaje de valores nulos por campo\n",
        "porcentaje_nulos = df.isnull().mean() * 100\n",
        "print(\"\\nPorcentaje de valores nulos por campo:\")\n",
        "print(porcentaje_nulos)\n",
        "\n",
        "# 3. Duplicados por id y por url\n",
        "duplicados_id = df.duplicated(subset=['id']).sum()\n",
        "duplicados_url = df.duplicated(subset=['url']).sum()\n",
        "print(f\"\\nDuplicados por id: {duplicados_id}\")\n",
        "print(f\"Duplicados por url: {duplicados_url}\")\n",
        "\n",
        "# 4. Consistencia en el formato de fechas y URLs\n",
        "# Fecha: formato esperado YYYY-MM-DD\n",
        "fecha_regex = re.compile(r'^\\d{4}-\\d{2}-\\d{2}$')\n",
        "fechas_validas = df['fecha'].apply(lambda x: bool(fecha_regex.match(str(x))))\n",
        "print(f\"\\nFechas con formato válido (YYYY-MM-DD): {fechas_validas.sum()} / {num_registros}\")\n",
        "\n",
        "# URL: debe empezar con http(s)://\n",
        "url_regex = re.compile(r'^https?://')\n",
        "urls_validas = df['url'].apply(lambda x: bool(url_regex.match(str(x))))\n",
        "print(f\"URLs con formato válido: {urls_validas.sum()} / {num_registros}\")\n",
        "\n",
        "# Mostrar resumen\n",
        "print(\"\\nResumen de calidad de datos:\")\n",
        "display(df.head())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "fundamentos-ingenieria-datos",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
